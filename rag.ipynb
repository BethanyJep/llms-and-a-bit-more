{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1001859",
   "metadata": {},
   "source": [
    "# Simple RAG Implementation with Constitution of Kenya\n",
    "\n",
    "This notebook implements a simple Retrieval-Augmented Generation (RAG) system using the Constitution of Kenya 2010 PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d972e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.3-cp39-abi3-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.11.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.13/site-packages (1.93.3)\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.7.1-cp313-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.7.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (4.14.1)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numpy>=1.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading numpy-2.3.1-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.13/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.13/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading pymupdf-1.26.3-cp39-abi3-macosx_11_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Using cached transformers-4.53.1-py3-none-any.whl (10.8 MB)\n",
      "Using cached huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "Using cached hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached faiss_cpu-1.11.0-cp313-cp313-macosx_14_0_arm64.whl (3.3 MB)\n",
      "Downloading numpy-2.3.1-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl (1.0 MB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
      "Using cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached torch-2.7.1-cp313-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached scikit_learn-1.7.0-cp313-cp313-macosx_12_0_arm64.whl (10.6 MB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached scipy-1.16.0-cp313-cp313-macosx_14_0_arm64.whl (20.7 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, setuptools, safetensors, regex, pyyaml, pymupdf, numpy, networkx, MarkupSafe, joblib, hf-xet, fsspec, filelock, tiktoken, scipy, jinja2, huggingface-hub, faiss-cpu, torch, tokenizers, scikit-learn, transformers, sentence-transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/25\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 faiss-cpu-1.11.0 filelock-3.18.0 fsspec-2025.5.1 hf-xet-1.1.5 huggingface-hub-0.33.2 jinja2-3.1.6 joblib-1.5.1 mpmath-1.3.0 networkx-3.5 numpy-2.3.1 pymupdf-1.26.3 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.16.0 sentence-transformers-5.0.0 setuptools-80.9.0 sympy-1.14.0 threadpoolctl-3.6.0 tiktoken-0.9.0 tokenizers-0.21.2 torch-2.7.1 transformers-4.53.1\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install pymupdf sentence-transformers faiss-cpu openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cceec536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pikachu/Downloads/llms-and-a-bit-more/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06ba0e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaded: 318999 characters\n",
      "First 300 characters: LAWS OF KENYA THE CONSTITUTION OF KENYA, 2010 Published by the National Council for Law Reporting with the Authority of the Attorney-General www.kenyalaw.org \n",
      "\n",
      "Constitution of Kenya, 2010 THE CONSTITUTION OF KENYA, 2010 ARRANGEMENT OF ARTICLES PREAMBLE CHAPTER ONE—SOVEREIGNTY OF THE PEOPLE AND SUPRE...\n"
     ]
    }
   ],
   "source": [
    "# Load PDF and extract text\n",
    "def load_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    \n",
    "    for page in doc:\n",
    "        page_text = page.get_text()\n",
    "        # Clean up text\n",
    "        page_text = re.sub(r'\\s+', ' ', page_text)\n",
    "        text += page_text + \"\\n\\n\"\n",
    "    \n",
    "    doc.close()\n",
    "    return text.strip()\n",
    "\n",
    "# Load the Constitution PDF\n",
    "pdf_path = \"/Users/pikachu/Downloads/llms-and-a-bit-more/The_Constitution_of_Kenya_2010.pdf\"\n",
    "constitution_text = load_pdf(pdf_path)\n",
    "\n",
    "print(f\"Document loaded: {len(constitution_text)} characters\")\n",
    "print(f\"First 300 characters: {constitution_text[:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ecbb3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 64 chunks\n",
      "Sample chunk: LAWS OF KENYA THE CONSTITUTION OF KENYA, 2010 Published by the National Council for Law Reporting with the Authority of the Attorney-General www.kenyalaw.org Constitution of Kenya, 2010 THE CONSTITUTI...\n"
     ]
    }
   ],
   "source": [
    "# Split text into chunks\n",
    "def split_text(text, chunk_size=1000, overlap=200):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "        \n",
    "        if i + chunk_size >= len(words):\n",
    "            break\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Create chunks\n",
    "chunks = split_text(constitution_text)\n",
    "print(f\"Created {len(chunks)} chunks\")\n",
    "print(f\"Sample chunk: {chunks[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f817db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "Generating embeddings...\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:00<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (64, 384)\n",
      "Embeddings created successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "print(\"Loading embedding model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"Generating embeddings...\")\n",
    "embeddings = model.encode(chunks, show_progress_bar=True)\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(\"Embeddings created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b0b63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up vector database...\n",
      "Vector database created with 64 vectors\n",
      "Ready for similarity search!\n"
     ]
    }
   ],
   "source": [
    "# Create vector database\n",
    "print(\"Setting up vector database...\")\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner product for similarity\n",
    "\n",
    "# Normalize embeddings for cosine similarity\n",
    "normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "index.add(normalized_embeddings.astype('float32'))\n",
    "\n",
    "print(f\"Vector database created with {index.ntotal} vectors\")\n",
    "print(\"Ready for similarity search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944379d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG query function ready!\n",
      "Use: query_constitution on citizenship to search the Constitution\n"
     ]
    }
   ],
   "source": [
    "# Simple RAG query function\n",
    "def query_constitution(question, k=3):\n",
    "    \"\"\"Query the Constitution and return relevant chunks\"\"\"\n",
    "    \n",
    "    # Create embedding for the question\n",
    "    question_embedding = model.encode([question])\n",
    "    \n",
    "    # Normalize question embedding\n",
    "    question_embedding = question_embedding / np.linalg.norm(question_embedding)\n",
    "    \n",
    "    # Search for similar chunks\n",
    "    scores, indices = index.search(question_embedding.astype('float32'), k)\n",
    "    \n",
    "    # Collect results\n",
    "    results = []\n",
    "    for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
    "        results.append({\n",
    "            'chunk': chunks[idx],\n",
    "            'score': float(score),\n",
    "            'rank': i + 1\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"RAG query function ready!\")\n",
    "print(\"Use: query_constitution on citizenship to search the Constitution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb1f1471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUESTION: What are the fundamental rights in Kenya?\n",
      "============================================================\n",
      "\n",
      "Rank 1 (Score: 0.719)\n",
      "Text: our ethnic, cultural and religious diversity, and determined to live in peace and unity as one indivisible sovereign nation: RESPECTFUL of the environment, which is our heritage, and determined to sustain it for the benefit of future generations: COMMITTED to nurturing and protecting the well-being ...\n",
      "----------------------------------------\n",
      "\n",
      "Rank 2 (Score: 0.696)\n",
      "Text: of Kenya in order to safeguard the well-being of the people of Kenya; (b) establishes a free and democratic system of Government that ensures good governance, constitutionalism, the rule of law, human rights and gender equity; (c) recognizes and demarcates divisions of responsibility among the vario...\n",
      "----------------------------------------\n",
      "\n",
      "Rank 3 (Score: 0.696)\n",
      "Text: LAWS OF KENYA THE CONSTITUTION OF KENYA, 2010 Published by the National Council for Law Reporting with the Authority of the Attorney-General www.kenyalaw.org Constitution of Kenya, 2010 THE CONSTITUTION OF KENYA, 2010 ARRANGEMENT OF ARTICLES PREAMBLE CHAPTER ONE—SOVEREIGNTY OF THE PEOPLE AND SUPREMA...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG system with sample questions\n",
    "sample_questions = [\n",
    "    \"What are the fundamental rights in Kenya?\",\n",
    "    \"How is the President elected?\",\n",
    "    \"What are the functions of county governments?\",\n",
    "    \"What is the role of Parliament?\"\n",
    "]\n",
    "\n",
    "# Function to display results nicely\n",
    "def display_results(question, results):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"QUESTION: {question}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    for result in results:\n",
    "        print(f\"\\nRank {result['rank']} (Score: {result['score']:.3f})\")\n",
    "        print(f\"Text: {result['chunk'][:300]}...\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Test with first question\n",
    "question = sample_questions[0]\n",
    "results = query_constitution(question)\n",
    "display_results(question, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
